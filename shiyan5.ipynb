{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ä¸€ã€åŠ è½½ Qwen1.5-0.5Bï¼ˆè¿œç¨‹åŠ è½½ï¼‰"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ¨¡å‹ Qwen/Qwen1.5-0.5B åŠ è½½å®Œæˆ\n",
      "æ¨¡å‹å‚æ•°é‡: 463.99M\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, TrainingArguments, Trainer\n",
    "from peft import LoraConfig, get_peft_model\n",
    "import json\n",
    "from datasets import Dataset\n",
    "import accelerate\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "model_name = \"Qwen/Qwen1.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, device_map=\"cpu\")\n",
    "print(f\"æ¨¡å‹ {model_name} åŠ è½½å®Œæˆ\")\n",
    "print(f\"æ¨¡å‹å‚æ•°é‡: {model.num_parameters()/1e6:.2f}M\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## äºŒã€Prompt è®¾è®¡é—®é¢˜\n",
    "\n",
    "### é—®é¢˜ 1ï¼šPrompt ç»“æ„è®¾è®¡\n",
    "\n",
    "åˆ†åˆ«é’ˆå¯¹**æ–‡æœ¬æ‘˜è¦**ã€**é—®é¢˜å›ç­”**ã€**è§’è‰²æ‰®æ¼”**ï¼Œè®¾è®¡3ç§ä¸åŒç±»å‹çš„Promptã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# å®šä¹‰ä¸‰ç§ä»»åŠ¡çš„Promptæ¨¡æ¿\n",
    "prompt_templates = {\n",
    "    # ä»»åŠ¡Aï¼šæ–‡æœ¬æ‘˜è¦ï¼ˆæ”¹è¿›ï¼šè¦æ±‚æ˜ç¡®å­—æ•°ï¼‰\n",
    "    \"summarization\": \"\"\"è¯·ç”¨50å­—å·¦å³æ¦‚æ‹¬ä»¥ä¸‹å†…å®¹ï¼Œéœ€åŒ…å«å…³é”®æ•°æ®ï¼š\n",
    "{input}\n",
    "ç²¾ç®€æ‘˜è¦ï¼š\"\"\",\n",
    "    \n",
    "    # ä»»åŠ¡Bï¼šé—®é¢˜å›ç­”ï¼ˆæ”¹è¿›ï¼šè¦æ±‚å®Œæ•´å›ç­”+ç»“æ„åŒ–è¾“å‡ºï¼‰\n",
    "    \"qa\": \"\"\"è¯·ä½œä¸ºä¸“ä¸šå¥åº·é¡¾é—®å®Œæ•´å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œè‡³å°‘åˆ—å‡º5ä¸ªè¦ç‚¹ï¼š\n",
    "é—®é¢˜ï¼š{input}\n",
    "å®Œæ•´å›ç­”ï¼š\"\"\",\n",
    "    \n",
    "    # ä»»åŠ¡Cï¼šè§’è‰²æ‰®æ¼”ï¼ˆæ”¹è¿›ï¼šæ˜ç¡®ä¸“ä¸šé¢†åŸŸï¼‰\n",
    "    \"role_playing\": \"\"\"ä½ æ˜¯ä¸€åä¸‰ç”²åŒ»é™¢å¿ƒå†…ç§‘ä¸»ä»»åŒ»å¸ˆï¼Œè¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„æ–¹å¼å›ç­”ï¼š\n",
    "æ‚£è€…é—®ï¼š{input}\n",
    "åŒ»ç”Ÿç­”ï¼š\"\"\"\n",
    "}\n",
    "def generate_response(prompt, max_length=300):\n",
    "    inputs = tokenizer(prompt, \n",
    "                      return_tensors=\"pt\",\n",
    "                      truncation=True,\n",
    "                      max_length=512)\n",
    "    \n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_length,  # å¢åŠ ç”Ÿæˆé•¿åº¦\n",
    "        do_sample=True,\n",
    "        temperature=0.7,\n",
    "        top_p=0.9,\n",
    "        num_beams=3,               # æŸæœç´¢æé«˜è´¨é‡\n",
    "        early_stopping=True,       # è‡ªç„¶åœæ­¢\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "        no_repeat_ngram_size=2     # é¿å…é‡å¤\n",
    "    )\n",
    "    \n",
    "    full_response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return full_response[len(prompt):]  # è¿”å›çº¯å›ç­”å†…å®¹\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é—®é¢˜ 2ï¼šPrompt åŒºåˆ«åˆ†æ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ä¸åŒPromptæ•ˆæœæµ‹è¯• ===\n",
      "=== æ”¹è¿›åçš„Promptæ•ˆæœæµ‹è¯• ===\n",
      "\n",
      "ã€summarizationã€‘Promptç»“æ„ï¼š\n",
      "è¯·ç”¨50å­—å·¦å³æ¦‚æ‹¬ä»¥ä¸‹å†…å®¹ï¼Œéœ€åŒ…å«å…³é”®æ•°æ®ï¼š\n",
      "\n",
      "æœ€æ–°å‘è¡¨åœ¨ã€Šç¾å›½å¿ƒè„ç—…å­¦æ‚å¿—ã€‹ä¸Šçš„ä¸€é¡¹é•¿æœŸè¿½è¸ªç ”ç©¶è¡¨æ˜ï¼Œæ¯æ—¥ä¿æŒ30åˆ†é’Ÿçš„ä¸­ç­‰å¼ºåº¦ä½“è‚²é”»ç‚¼ï¼Œå¦‚å¿«èµ°ã€æ¸¸æ³³æˆ–éª‘è‡ªè¡Œè½¦ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¿ƒè¡€ç®¡ç–¾ç—…å‘ç—…é£é™©çº¦35-40%ã€‚è¿™é¡¹ç ”ç©¶è·Ÿè¸ªäº†è¶…è¿‡12,000åå¹´é¾„åœ¨40-75å²ä¹‹é—´çš„å‚ä¸è€…ï¼Œå†æ—¶15å¹´ã€‚\n",
      "\n",
      "ç ”ç©¶è´Ÿè´£äººã€å“ˆä½›åŒ»å­¦é™¢çš„çº¦ç¿°Â·å²å¯†æ–¯æ•™æˆæŒ‡å‡ºï¼Œè§„å¾‹è¿åŠ¨ä¸ä»…å¯¹å¿ƒè„å¥åº·æœ‰ç›Šï¼Œè¿˜èƒ½æœ‰æ•ˆç¼“è§£ç„¦è™‘å’ŒæŠ‘éƒç—‡çŠ¶ã€‚æ•°æ®åˆ†ææ˜¾ç¤ºï¼ŒåšæŒé”»ç‚¼çš„å‚ä¸è€…å¿ƒç†å¥åº·è¯„åˆ†å¹³å‡æé«˜äº†22%ï¼Œç¡çœ è´¨é‡ä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ã€‚\n",
      "\n",
      "æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°ï¼Œè¿åŠ¨å¸¦æ¥çš„å¥åº·æ•ˆç›Šå…·æœ‰ç´¯ç§¯æ•ˆåº”ã€‚æ¯å‘¨ç´¯è®¡150åˆ†é’Ÿçš„è¿åŠ¨æ—¶é—´ï¼Œåˆ†æ•£åœ¨3-5å¤©å†…å®Œæˆï¼Œå°±èƒ½è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚å²å¯†æ–¯æ•™æˆç‰¹åˆ«å¼ºè°ƒï¼Œå¯¹äºä¹…åä¸åŠ¨çš„åŠå…¬å®¤äººç¾¤ï¼Œå³ä½¿åªæ˜¯æ¯éš”ä¸€å°æ—¶ç«™èµ·æ¥æ´»åŠ¨5åˆ†é’Ÿï¼Œä¹Ÿèƒ½å¸¦æ¥æ˜æ˜¾çš„å¥åº·æ”¹å–„ã€‚\n",
      "\n",
      "è¿™é¡¹ç ”ç©¶çš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒè¯å®äº†é€‚åº¦è¿åŠ¨æ¯”é«˜å¼ºåº¦è®­ç»ƒæ›´é€‚åˆæ™®é€šäººç¾¤ã€‚ç ”ç©¶å›¢é˜Ÿå»ºè®®ï¼Œå…¬å…±å«ç”Ÿæ”¿ç­–åº”è¯¥æ›´åŠ é‡è§†æ¨å¹¿è¿™ç§ç®€å•æ˜“è¡Œçš„å¥åº·ç”Ÿæ´»æ–¹å¼ï¼Œè€Œä¸æ˜¯è¿‡åº¦å¼ºè°ƒéœ€è¦ä¸“ä¸šæŒ‡å¯¼çš„é«˜å¼ºåº¦è®­ç»ƒã€‚\n",
      "\n",
      "ç²¾ç®€æ‘˜è¦ï¼š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æ¨¡å‹å›ç­”ï¼š\n",
      "æœ€æ–°ç ”ç©¶è¯æ˜ï¼Œæ¯å¤©ä¿æŒåŠå°æ—¶çš„æœ‰æ°§è¿åŠ¨å¯ä»¥é™ä½å¿ƒè„ç—…å’Œä¸­é£çš„é£é™©ã€‚è¯¥ç ”ç©¶è¿½è¸ªäº†è¿‘1.2ä¸‡åå‚ä¸è€…ï¼Œå¹¶å‘ç°æ¯å‘¨è‡³å°‘é”»ç‚¼3æ¬¡æˆ–5æ¬¡çš„äººç¾¤ï¼Œå…¶å¿ƒç†å¥åº·å’Œç¡çœ è¡¨ç°æ›´å¥½ã€‚\n",
      "==================================================\n",
      "\n",
      "ã€qaã€‘Promptç»“æ„ï¼š\n",
      "è¯·ä½œä¸ºä¸“ä¸šå¥åº·é¡¾é—®å®Œæ•´å›ç­”ä»¥ä¸‹é—®é¢˜ï¼Œè‡³å°‘åˆ—å‡º5ä¸ªè¦ç‚¹ï¼š\n",
      "é—®é¢˜ï¼šå¦‚ä½•ä¿æŒå¿ƒè„å¥åº·ï¼Ÿ\n",
      "å®Œæ•´å›ç­”ï¼š\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "æ¨¡å‹å›ç­”ï¼š\n",
      " 1. é¥®é£Ÿå¥åº·ï¼šä¿æŒå‡è¡¡çš„é¥®é£Ÿï¼Œæ‘„å…¥è¶³å¤Ÿçš„è›‹ç™½è´¨ã€ç¢³æ°´åŒ–åˆç‰©ã€è„‚è‚ªã€ç»´ç”Ÿç´ å’ŒçŸ¿ç‰©è´¨ã€‚\n",
      "2. é”»ç‚¼èº«ä½“ï¼šæ¯å‘¨è‡³å°‘è¿›è¡Œ150åˆ†é’Ÿçš„ä¸­ç­‰å¼ºåº¦æœ‰æ°§è¿åŠ¨ï¼Œå¦‚å¿«èµ°ã€æ…¢è·‘ã€æ¸¸æ³³ã€éª‘è‡ªè¡Œè½¦ç­‰ã€‚\n",
      "3. æ§åˆ¶ä½“é‡ï¼šè¿‡é‡æˆ–è‚¥èƒ–ä¼šå¢åŠ å¿ƒè„ç–¾ç—…çš„é£é™©ï¼Œå› æ­¤éœ€è¦æ§åˆ¶ä½“é‡ã€‚\n",
      "4. æˆ’çƒŸé™é…’ï¼šå¸çƒŸå’Œé¥®é…’ä¼šæŸå®³å¿ƒè„ï¼Œåº”å°½é‡é¿å…ã€‚\n",
      "5. å®šæœŸä½“æ£€ï¼šå®šæœŸè¿›è¡Œå¿ƒç”µå›¾ã€è¡€å‹ã€è¡€è„‚ã€è¡€ç³–ç­‰æ£€æŸ¥ï¼ŒåŠæ—¶å‘ç°å’Œæ²»ç–—æ½œåœ¨çš„å¥åº·é—®é¢˜ã€‚\n",
      "==================================================\n",
      "\n",
      "ã€role_playingã€‘Promptç»“æ„ï¼š\n",
      "ä½ æ˜¯ä¸€åä¸‰ç”²åŒ»é™¢å¿ƒå†…ç§‘ä¸»ä»»åŒ»å¸ˆï¼Œè¯·ç”¨ä¸“ä¸šä½†æ˜“æ‡‚çš„æ–¹å¼å›ç­”ï¼š\n",
      "æ‚£è€…é—®ï¼šå¦‚ä½•ä¿æŒå¿ƒè„å¥åº·ï¼Ÿ\n",
      "åŒ»ç”Ÿç­”ï¼š\n",
      "\n",
      "æ¨¡å‹å›ç­”ï¼š\n",
      "ä¿æŒå¥åº·çš„å¿ƒè„éœ€è¦è‰¯å¥½çš„ç”Ÿæ´»ä¹ æƒ¯å’Œé¥®é£Ÿä¹ æƒ¯ã€‚é¦–å…ˆï¼Œè¦ä¿è¯å……è¶³çš„ç¡çœ ï¼Œæ¯å¤©ç¡çœ æ—¶é—´ä¸å°‘äº7å°æ—¶ã€‚å…¶æ¬¡ï¼Œé¥®é£Ÿè¦å‡è¡¡ï¼Œå¤šåƒæ–°é²œè”¬èœå’Œæ°´æœï¼Œå°‘åƒé«˜è„‚è‚ªã€é«˜çƒ­é‡çš„é£Ÿç‰©ï¼Œå¦‚æ²¹ç‚¸é£Ÿå“ã€ç”œé£Ÿç­‰ã€‚æ­¤å¤–ï¼Œè¿˜è¦æˆ’çƒŸæˆ’é…’ï¼Œé¿å…è¿‡åº¦åŠ³ç´¯å’Œæƒ…ç»ªæ³¢åŠ¨ã€‚æœ€åï¼Œå®šæœŸè¿›è¡Œä½“æ£€å’Œå¿ƒç”µå›¾æ£€æŸ¥ï¼ŒåŠæ—¶å‘ç°å’Œæ²»ç–—å¿ƒè„ç–¾ç—…ã€‚\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "test_input = \"\"\"\n",
    "æœ€æ–°å‘è¡¨åœ¨ã€Šç¾å›½å¿ƒè„ç—…å­¦æ‚å¿—ã€‹ä¸Šçš„ä¸€é¡¹é•¿æœŸè¿½è¸ªç ”ç©¶è¡¨æ˜ï¼Œæ¯æ—¥ä¿æŒ30åˆ†é’Ÿçš„ä¸­ç­‰å¼ºåº¦ä½“è‚²é”»ç‚¼ï¼Œå¦‚å¿«èµ°ã€æ¸¸æ³³æˆ–éª‘è‡ªè¡Œè½¦ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¿ƒè¡€ç®¡ç–¾ç—…å‘ç—…é£é™©çº¦35-40%ã€‚è¿™é¡¹ç ”ç©¶è·Ÿè¸ªäº†è¶…è¿‡12,000åå¹´é¾„åœ¨40-75å²ä¹‹é—´çš„å‚ä¸è€…ï¼Œå†æ—¶15å¹´ã€‚\n",
    "\n",
    "ç ”ç©¶è´Ÿè´£äººã€å“ˆä½›åŒ»å­¦é™¢çš„çº¦ç¿°Â·å²å¯†æ–¯æ•™æˆæŒ‡å‡ºï¼Œè§„å¾‹è¿åŠ¨ä¸ä»…å¯¹å¿ƒè„å¥åº·æœ‰ç›Šï¼Œè¿˜èƒ½æœ‰æ•ˆç¼“è§£ç„¦è™‘å’ŒæŠ‘éƒç—‡çŠ¶ã€‚æ•°æ®åˆ†ææ˜¾ç¤ºï¼ŒåšæŒé”»ç‚¼çš„å‚ä¸è€…å¿ƒç†å¥åº·è¯„åˆ†å¹³å‡æé«˜äº†22%ï¼Œç¡çœ è´¨é‡ä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ã€‚\n",
    "\n",
    "æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°ï¼Œè¿åŠ¨å¸¦æ¥çš„å¥åº·æ•ˆç›Šå…·æœ‰ç´¯ç§¯æ•ˆåº”ã€‚æ¯å‘¨ç´¯è®¡150åˆ†é’Ÿçš„è¿åŠ¨æ—¶é—´ï¼Œåˆ†æ•£åœ¨3-5å¤©å†…å®Œæˆï¼Œå°±èƒ½è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚å²å¯†æ–¯æ•™æˆç‰¹åˆ«å¼ºè°ƒï¼Œå¯¹äºä¹…åä¸åŠ¨çš„åŠå…¬å®¤äººç¾¤ï¼Œå³ä½¿åªæ˜¯æ¯éš”ä¸€å°æ—¶ç«™èµ·æ¥æ´»åŠ¨5åˆ†é’Ÿï¼Œä¹Ÿèƒ½å¸¦æ¥æ˜æ˜¾çš„å¥åº·æ”¹å–„ã€‚\n",
    "\n",
    "è¿™é¡¹ç ”ç©¶çš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒè¯å®äº†é€‚åº¦è¿åŠ¨æ¯”é«˜å¼ºåº¦è®­ç»ƒæ›´é€‚åˆæ™®é€šäººç¾¤ã€‚ç ”ç©¶å›¢é˜Ÿå»ºè®®ï¼Œå…¬å…±å«ç”Ÿæ”¿ç­–åº”è¯¥æ›´åŠ é‡è§†æ¨å¹¿è¿™ç§ç®€å•æ˜“è¡Œçš„å¥åº·ç”Ÿæ´»æ–¹å¼ï¼Œè€Œä¸æ˜¯è¿‡åº¦å¼ºè°ƒéœ€è¦ä¸“ä¸šæŒ‡å¯¼çš„é«˜å¼ºåº¦è®­ç»ƒã€‚\n",
    "\"\"\"\n",
    "print(\"\\n=== ä¸åŒPromptæ•ˆæœæµ‹è¯• ===\")\n",
    "test_question = \"å¦‚ä½•ä¿æŒå¿ƒè„å¥åº·ï¼Ÿ\"\n",
    "test_article = \"\"\"\n",
    "æœ€æ–°å‘è¡¨åœ¨ã€Šç¾å›½å¿ƒè„ç—…å­¦æ‚å¿—ã€‹ä¸Šçš„ä¸€é¡¹é•¿æœŸè¿½è¸ªç ”ç©¶è¡¨æ˜ï¼Œæ¯æ—¥ä¿æŒ30åˆ†é’Ÿçš„ä¸­ç­‰å¼ºåº¦ä½“è‚²é”»ç‚¼ï¼Œå¦‚å¿«èµ°ã€æ¸¸æ³³æˆ–éª‘è‡ªè¡Œè½¦ï¼Œèƒ½å¤Ÿæ˜¾è‘—é™ä½å¿ƒè¡€ç®¡ç–¾ç—…å‘ç—…é£é™©çº¦35-40%ã€‚è¿™é¡¹ç ”ç©¶è·Ÿè¸ªäº†è¶…è¿‡12,000åå¹´é¾„åœ¨40-75å²ä¹‹é—´çš„å‚ä¸è€…ï¼Œå†æ—¶15å¹´ã€‚\n",
    "\n",
    "ç ”ç©¶è´Ÿè´£äººã€å“ˆä½›åŒ»å­¦é™¢çš„çº¦ç¿°Â·å²å¯†æ–¯æ•™æˆæŒ‡å‡ºï¼Œè§„å¾‹è¿åŠ¨ä¸ä»…å¯¹å¿ƒè„å¥åº·æœ‰ç›Šï¼Œè¿˜èƒ½æœ‰æ•ˆç¼“è§£ç„¦è™‘å’ŒæŠ‘éƒç—‡çŠ¶ã€‚æ•°æ®åˆ†ææ˜¾ç¤ºï¼ŒåšæŒé”»ç‚¼çš„å‚ä¸è€…å¿ƒç†å¥åº·è¯„åˆ†å¹³å‡æé«˜äº†22%ï¼Œç¡çœ è´¨é‡ä¹Ÿæœ‰æ˜æ˜¾æ”¹å–„ã€‚\n",
    "\n",
    "æ­¤å¤–ï¼Œç ”ç©¶è¿˜å‘ç°ï¼Œè¿åŠ¨å¸¦æ¥çš„å¥åº·æ•ˆç›Šå…·æœ‰ç´¯ç§¯æ•ˆåº”ã€‚æ¯å‘¨ç´¯è®¡150åˆ†é’Ÿçš„è¿åŠ¨æ—¶é—´ï¼Œåˆ†æ•£åœ¨3-5å¤©å†…å®Œæˆï¼Œå°±èƒ½è¾¾åˆ°æœ€ä½³æ•ˆæœã€‚å²å¯†æ–¯æ•™æˆç‰¹åˆ«å¼ºè°ƒï¼Œå¯¹äºä¹…åä¸åŠ¨çš„åŠå…¬å®¤äººç¾¤ï¼Œå³ä½¿åªæ˜¯æ¯éš”ä¸€å°æ—¶ç«™èµ·æ¥æ´»åŠ¨5åˆ†é’Ÿï¼Œä¹Ÿèƒ½å¸¦æ¥æ˜æ˜¾çš„å¥åº·æ”¹å–„ã€‚\n",
    "\n",
    "è¿™é¡¹ç ”ç©¶çš„é‡è¦æ„ä¹‰åœ¨äºï¼Œå®ƒè¯å®äº†é€‚åº¦è¿åŠ¨æ¯”é«˜å¼ºåº¦è®­ç»ƒæ›´é€‚åˆæ™®é€šäººç¾¤ã€‚ç ”ç©¶å›¢é˜Ÿå»ºè®®ï¼Œå…¬å…±å«ç”Ÿæ”¿ç­–åº”è¯¥æ›´åŠ é‡è§†æ¨å¹¿è¿™ç§ç®€å•æ˜“è¡Œçš„å¥åº·ç”Ÿæ´»æ–¹å¼ï¼Œè€Œä¸æ˜¯è¿‡åº¦å¼ºè°ƒéœ€è¦ä¸“ä¸šæŒ‡å¯¼çš„é«˜å¼ºåº¦è®­ç»ƒã€‚\n",
    "\"\"\"\n",
    "\n",
    "print(\"=== æ”¹è¿›åçš„Promptæ•ˆæœæµ‹è¯• ===\")\n",
    "for task_name, template in prompt_templates.items():\n",
    "    input_content = test_question if task_name != \"summarization\" else test_article\n",
    "    prompt = template.format(input=input_content)\n",
    "    \n",
    "    print(f\"\\nã€{task_name}ã€‘Promptç»“æ„ï¼š\\n{prompt}\")\n",
    "    \n",
    "    response = generate_response(prompt)\n",
    "    \n",
    "    # å®Œæ•´æ€§æ£€æŸ¥ï¼ˆæ–°å¢åŠŸèƒ½ï¼‰\n",
    "    if not response.endswith((\"ã€‚\", \"ï¼\", \"ï¼Ÿ\")):\n",
    "        print(\"âš ï¸ æ£€æµ‹åˆ°å›ç­”ä¸å®Œæ•´ï¼Œå°è¯•è¡¥å……...\")\n",
    "        continuation = generate_response(prompt + response, max_length=100)\n",
    "        response += continuation\n",
    "    \n",
    "    print(f\"\\næ¨¡å‹å›ç­”ï¼š\\n{response}\\n{'='*50}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### ä»»åŠ¡ 2ï¼šæ¢ç´¢ Prompt å½±å“\n",
    "\n",
    "#### é—®é¢˜ 3ï¼šæœ€çŸ­ Prompt\n",
    "æ‰¾åˆ°æœ€çŸ­ä»ç„¶èƒ½ç†è§£çš„Promptï¼š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€é—®ç­”ã€‘Prompt: 'å…‰é€Ÿï¼Ÿ'\n",
      "   â†’ ï¼ˆã€€ã€€ï¼‰\n",
      "A. 10m/s\n",
      "B. çº¦11.2km/sï¼ˆ1m=1Ã—18kmï¼‰\n",
      "C. å¤§çº¦1å…‰å¹´\n",
      "D. å°äº1km/h\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€æ‘˜è¦ã€‘Prompt: 'æ¦‚æ‹¬ï¼šå…‰é€Ÿ'\n",
      "   â†’ æ˜¯å®‡å®™ä¸­æœ€å¿«çš„é€Ÿåº¦ï¼Œæ˜¯äººç±»ç›®å‰æ‰€èƒ½è§‚æµ‹åˆ°çš„æœ€å¿«é€Ÿåº¦ã€‚å…‰çš„é€Ÿåº¦æ˜¯æ¯ç§’299792458ç±³ï¼Œçº¦ä¸ºæ¯ç§’é’Ÿ300äº¿å…¬é‡Œã€‚åœ¨å®‡å®™ä¸­çš„ä»»ä½•åœ°æ–¹ï¼Œå…‰éƒ½å¯ä»¥ä»¥\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ç¿»è¯‘ã€‘Prompt: 'è‹±â†’ä¸­ï¼šhello'\n",
      "   â†’ â†’hello\n",
      "æ•…ç­”æ¡ˆä¸ºï¼šHelloï¼\n",
      "è§£æï¼šä½ å¥½ï¼Œä½ å¥½ï¼\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:151643 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ã€ä»£ç ã€‘Prompt: 'pyæ‰“å°hello'\n",
      "   â†’ world\n",
      "print(\"hello\")\n",
      "print(\"\")\n",
      "print(\"\\n\")\n",
      "# 1. 2.3.4.5.6.7.8.9.10.\n",
      "\n",
      "ã€æç®€ã€‘Prompt: 'å…‰é€Ÿ'\n",
      "   â†’ ä¸º3Ã—108m/sï¼Œå…‰åœ¨çœŸç©ºä¸­ä¼ æ’­çš„é€Ÿåº¦ä¸ºc=3.0Ã— 1 0 8 m/sï¼Œåˆ™å…‰ä»åœ°çƒåˆ°æœˆçƒéœ€è¦çš„æ—¶é—´ä¸ºï¼ˆã€€ã€€ï¼‰\n",
      "A. 2.5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen1.5-0.5B\", device_map=\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen1.5-0.5B\")\n",
    "\n",
    "# æœ€å°åŒ–Promptæµ‹è¯•é›†\n",
    "minimal_prompts = [\n",
    "    (\"é—®ç­”\", \"å…‰é€Ÿï¼Ÿ\"),          # 3å­—ç¬¦\n",
    "    (\"æ‘˜è¦\", \"æ¦‚æ‹¬ï¼šå…‰é€Ÿ\"),      # 5å­—ç¬¦ \n",
    "    (\"ç¿»è¯‘\", \"è‹±â†’ä¸­ï¼šhello\"),    # 6å­—ç¬¦\n",
    "    (\"ä»£ç \", \"pyæ‰“å°hello\"),     # 7å­—ç¬¦\n",
    "    (\"æç®€\", \"å…‰é€Ÿ\")            # 2å­—ç¬¦ï¼ˆæµ‹è¯•ä¸‹é™ï¼‰\n",
    "]\n",
    "\n",
    "for task, prompt in minimal_prompts:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "    outputs = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=50,\n",
    "        no_repeat_ngram_size=2,\n",
    "        early_stopping=True\n",
    "    )\n",
    "    response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    print(f\"ã€{task}ã€‘Prompt: '{prompt}'\\n   â†’ {response[len(prompt):].strip()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### é—®é¢˜ 4ï¼šæ”¹å˜ Prompt è¯­æ°”\n",
    "å¦‚å¢åŠ â€œè¯·è¯¦ç»†å›ç­”â€ï¼Œå¯¹è¾“å‡ºæœ‰ä½•å½±å“ï¼Ÿ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ä¿®æ­£ç‰ˆè¯­æ°”å½±å“æµ‹è¯• ===\n",
      "\n",
      "ğŸ”¹ ç®€æ´ç‰ˆ Prompt: 'è¯·ç”¨1å¥è¯ç®€å•å›ç­”ï¼šæ°´çš„åŒ–å­¦åˆ†å­å¼æ˜¯ä»€ä¹ˆ?'\n",
      "ğŸ’¡ æ¨¡å‹å›ç­”:\n",
      "æ°´çš„åˆ†å­ç»“æ„æ˜¯H2Oï¼Œç”±ä¸¤ä¸ªæ°¢åŸå­å’Œä¸€ä¸ªæ°§åŸå­ç»„æˆã€‚\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ”¹ ä¸“ä¸šç‰ˆ Prompt: 'è¯·ç”¨ä¸“ä¸šæœ¯è¯­åˆ†ç‚¹è§£é‡Šï¼šæ°´çš„åŒ–å­¦åˆ†å­å¼æ˜¯ä»€ä¹ˆ?\n",
      "1.'\n",
      "ğŸ’¡ æ¨¡å‹å›ç­”:\n",
      "æ°´åˆ†å­ç”±ä¸¤ä¸ªæ°¢åŸå­å’Œä¸€ä¸ªæ°§åŸå­ç»„æˆã€‚\n",
      "2. åœ¨æ°´åˆ†å­ä¸­ï¼Œæ°¢å’Œæ°§çš„åŸå­ä¸ªæ•°æ¯”ä¸º1:2ï¼Œå³1ä¸ªæ°¢åˆ†å­å’Œ2ä¸ªæ°§åˆ†å­ã€‚\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ”¹ é€šä¿—ç‰ˆ Prompt: 'ç”¨å°å­¦ç”Ÿèƒ½å¬æ‡‚çš„è¯å›ç­”ï¼šæ°´çš„åŒ–å­¦åˆ†å­å¼æ˜¯ä»€ä¹ˆ?'\n",
      "ğŸ’¡ æ¨¡å‹å›ç­”:\n",
      "æ°´åˆ†å­çš„ç»“æ„å¼æ˜¯æ€æ ·çš„?\n",
      "\n",
      "æ°´æ˜¯H2O,åˆ†å­ä¸­HåŸå­å’ŒOåŸå­ä»¥å…±ä»·é”®ç»“åˆ,è€ŒOå’ŒHä¹‹é—´ä»¥éææ€§é”®ç›¸è¿,æ‰€ä»¥æ°´æ˜¯ä¸€ç§åŒåŸå­åˆ†å­,å…¶ç»“æ„ç®€å¼ä¸ºH-O-O-H.\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ”¹ ä¸¥è°¨ç‰ˆ Prompt: 'æ°´çš„åŒ–å­¦åˆ†å­å¼æ˜¯ä»€ä¹ˆ?ï¼ˆéœ€æä¾›3ä¸ªç§‘å­¦ä¾æ®ï¼‰'\n",
      "ğŸ’¡ æ¨¡å‹å›ç­”:\n",
      "æ°´çš„åˆ†å­ç»“æ„æ˜¯H2O,åˆ†å­é‡æ˜¯18,æ°´åˆ†å­ä¸­æ°¢åŸå­å’Œæ°§åŸå­çš„ä¸ªæ•°æ¯”æ˜¯2:1,æ‰€ä»¥æ°´æ˜¯åŒåŸå­åˆ†å­,åŒ–å­¦å¼æ˜¯ H2 O, æ¯ä¸ªæ°´åŸå­çš„è´¨é‡æ˜¯ 1.80614Ã—10-26kg,æ¯ä¸ªæ°´ç¦»å­çš„è´¨é‡ä¸º 3.2035Ã—  2 6  kg, ä¸€ä¸ªæ°´æ°”åˆ†å­çš„è´¨é‡ 0.001278Ã—22.4  g,ä¸€ä¸ªæ°¢ç¦»å­è´¨é‡ 9.11Ã—3 4 g  æ±‚æ°´åœ¨æ°´æº¶æ¶²ä¸­ç”µç¦»å‡ºçš„ç¦»å­çš„ç‰©è´¨çš„é‡æµ“åº¦,\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n",
      "\n",
      "ğŸ”¹ è§’è‰²ç‰ˆ Prompt: 'ä½ æ˜¯æœ‰30å¹´ç»éªŒçš„åŒ–å­¦æ•™æˆï¼Œæ­£åœ¨ç»™å¤§å­¦ç”Ÿæˆè¯¾ã€‚å­¦ç”Ÿé—®ï¼šæ°´çš„åŒ–å­¦åˆ†å­å¼æ˜¯ä»€ä¹ˆ?'\n",
      "ğŸ’¡ æ¨¡å‹å›ç­”:\n",
      "æ•™æˆå›ç­”ï¼šæ˜¯H2Oã€‚ä½ è®¤ä¸ºæ•™æˆçš„å›ç­”æ˜¯ï¼ˆ ï¼‰ã€‚\n",
      "A. é”™è¯¯çš„ï¼Œå› ä¸ºæ°´åˆ†å­ä¸­æ²¡æœ‰æ°¢åŸå­\n",
      "B. æ­£ç¡®çš„ï¼Œåœ¨æ°´æº¶æ¶²ä¸­ï¼Œæ°¢ç¦»å­å’Œæ°¢æ°§æ ¹ç¦»å­ä»¥ç¦»å­é”®ç»“åˆ\n",
      "C. æœ‰è¯¯ï¼Œæ°´æ˜¯å…±ä»·åŒ–åˆç‰©\n",
      "D. ä¸ç¡®å®šï¼Œè¦çœ‹æ°´æ˜¯ä»€ä¹ˆçŠ¶æ€\n",
      "ç­”æ¡ˆï¼šB\n",
      "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
     ]
    }
   ],
   "source": [
    "tone_variations = [\n",
    "    {\"name\": \"ç®€æ´ç‰ˆ\", \"prompt\": \"è¯·ç”¨1å¥è¯ç®€å•å›ç­”ï¼š{input}\", \"params\": {\"temperature\": 0.3}},\n",
    "    {\"name\": \"ä¸“ä¸šç‰ˆ\", \"prompt\": \"è¯·ç”¨ä¸“ä¸šæœ¯è¯­åˆ†ç‚¹è§£é‡Šï¼š{input}\\n1.\", \"params\": {\"temperature\": 0.5, \"num_beams\": 3}},\n",
    "    {\"name\": \"é€šä¿—ç‰ˆ\", \"prompt\": \"ç”¨å°å­¦ç”Ÿèƒ½å¬æ‡‚çš„è¯å›ç­”ï¼š{input}\", \"params\": {\"top_k\": 40}},\n",
    "    {\"name\": \"ä¸¥è°¨ç‰ˆ\", \"prompt\": \"{input}ï¼ˆéœ€æä¾›3ä¸ªç§‘å­¦ä¾æ®ï¼‰\", \"params\": {\"do_sample\": False}},\n",
    "    {\"name\": \"è§’è‰²ç‰ˆ\", \"prompt\": \"ä½ æ˜¯æœ‰30å¹´ç»éªŒçš„åŒ–å­¦æ•™æˆï¼Œæ­£åœ¨ç»™å¤§å­¦ç”Ÿæˆè¯¾ã€‚å­¦ç”Ÿé—®ï¼š{input}\", \"params\": {\"num_return_sequences\": 1}}\n",
    "]\n",
    "\n",
    "print(\"\\n=== ä¿®æ­£ç‰ˆè¯­æ°”å½±å“æµ‹è¯• ===\")\n",
    "for tone in tone_variations:\n",
    "    prompt = tone[\"prompt\"].format(input=\"æ°´çš„åŒ–å­¦åˆ†å­å¼æ˜¯ä»€ä¹ˆ?\")\n",
    "    print(f\"\\nğŸ”¹ {tone['name']} Prompt: '{prompt}'\")\n",
    "    \n",
    "    # ä¿®æ­£çš„è¾“å…¥å¤„ç†\n",
    "    inputs = tokenizer(\n",
    "        prompt,\n",
    "        return_tensors=\"pt\",\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        max_length=512\n",
    "    )\n",
    "    \n",
    "    # åŠ¨æ€ç”Ÿæˆå‚æ•°\n",
    "    base_params = {\n",
    "        **inputs,\n",
    "        \"max_new_tokens\": 150,\n",
    "        \"early_stopping\": True,\n",
    "        \"eos_token_id\": tokenizer.eos_token_id,\n",
    "        \"pad_token_id\": tokenizer.eos_token_id,\n",
    "        \"no_repeat_ngram_size\": 2,  # é˜²æ­¢é‡å¤\n",
    "        \"num_beams\": 1\n",
    "    }\n",
    "    params = {**base_params, **tone[\"params\"]}\n",
    "    \n",
    "    try:\n",
    "        outputs = model.generate(**params)\n",
    "        response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        # æå–ç”Ÿæˆéƒ¨åˆ†ï¼ˆå»é™¤Promptï¼‰\n",
    "        generated = response[len(prompt):].strip()\n",
    "        \n",
    "        # äºŒæ¬¡æ ¡éªŒï¼ˆé˜²æ­¢æˆªæ–­ï¼‰\n",
    "        if not generated or len(generated) < 3:\n",
    "            raise ValueError(\"ç”Ÿæˆå†…å®¹è¿‡çŸ­\")\n",
    "            \n",
    "        print(f\"ğŸ’¡ æ¨¡å‹å›ç­”:\\n{generated}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ ç”Ÿæˆå¤±è´¥: {str(e)}\")\n",
    "    \n",
    "    print(\"â”\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "## ä¸‰ã€LoRA å¾®è°ƒé—®é¢˜\n",
    "\n",
    "### LoRA ç›¸å…³åº“ä¸é…ç½®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, Trainer, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from peft import LoraConfig, get_peft_model, PeftModel\n",
    "from datasets import load_dataset\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 1. åŠ è½½Tokenizerå’Œæ¨¡å‹\n",
    "model_name = \"Qwen/Qwen1.5-0.5B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### åŠ è½½è®­ç»ƒæ•°æ®\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 192/192 [00:00<00:00, 2335.43 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "# å‡è®¾ä½ çš„æ•°æ®æ–‡ä»¶ä¸º train.jsonlï¼Œæ ¼å¼ä¸ºæ¯è¡Œä¸€ä¸ª{\"input\": \"...\", \"output\": \"...\"}\n",
    "data = load_dataset(\"json\", data_files=\"train_data.json\")[\"train\"]\n",
    "\n",
    "def preprocess(example):\n",
    "    prompt = example[\"input\"]\n",
    "    answer = example[\"output\"]\n",
    "    full_prompt = prompt + tokenizer.eos_token + answer + tokenizer.eos_token\n",
    "    tokenized = tokenizer(\n",
    "        full_prompt, \n",
    "        truncation=True, \n",
    "        padding=\"max_length\",  # å¼ºåˆ¶æ‰€æœ‰æ ·æœ¬ç»Ÿä¸€ä¸ºæœ€å¤§é•¿åº¦\n",
    "        max_length=512         # æ ¹æ®æ¨¡å‹æœ€å¤§æ”¯æŒé•¿åº¦è°ƒæ•´\n",
    "    )\n",
    "    tokenized[\"labels\"] = tokenized[\"input_ids\"].copy()  # ç¡®ä¿ labels ä¸ input_ids å¯¹é½\n",
    "    return tokenized\n",
    "\n",
    "tokenized_data = data.map(\n",
    "    preprocess,\n",
    "    remove_columns=data.column_names  # åˆ é™¤åŸå§‹ input/output åˆ—ï¼Œé¿å…å¹²æ‰°\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ç›®å½• 'lora-5epoch' å­˜åœ¨: False\n",
      "âœ— ç›®å½•å†™å…¥å¤±è´¥: [Errno 2] No such file or directory: 'lora-5epoch\\\\test.txt'\n"
     ]
    }
   ],
   "source": [
    "# æ£€æŸ¥ç›®å½•æƒé™\n",
    "print(f\"ç›®å½• 'lora-5epoch' å­˜åœ¨: {os.path.exists('lora-5epoch')}\")\n",
    "try:\n",
    "    # å°è¯•åˆ›å»ºæµ‹è¯•æ–‡ä»¶\n",
    "    with open(os.path.join('lora-5epoch', 'test.txt'), 'w') as f:\n",
    "        f.write('test')\n",
    "    print(\"âœ“ ç›®å½•å¯å†™å…¥\")\n",
    "    # æ¸…ç†æµ‹è¯•æ–‡ä»¶\n",
    "    os.remove(os.path.join('lora-5epoch', 'test.txt'))\n",
    "except Exception as e:\n",
    "    print(f\"âœ— ç›®å½•å†™å…¥å¤±è´¥: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LoRA å¾®è°ƒè®­ç»ƒä»£ç \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No label_names provided for model class `PeftModel`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='240' max='240' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [240/240 46:47, Epoch 5/5]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.048100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.934600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.739500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.155400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3.217600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.772700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.117200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.306800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.451700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.144800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.191800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>1.718200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>1.645900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1.408300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.204300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.195400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>1.927000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.230200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.422200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>1.499800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>1.561800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>1.066800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>1.590600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>1.010900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>0.978700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>1.496800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.350200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.218300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>0.727400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.109500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>0.766800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>1.378900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.294900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>0.756100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>0.853000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>0.708500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.462400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>1.309000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>0.883400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.300700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.622200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.637200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.428400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.989900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.323800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.312500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.840400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.346000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.021800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.930000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.292000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.021300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>0.915400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.480100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>0.736400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.024800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.447300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.291700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>2.156900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.044500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>61</td>\n",
       "      <td>1.078300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>62</td>\n",
       "      <td>1.467900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>63</td>\n",
       "      <td>1.652400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>64</td>\n",
       "      <td>0.634700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>65</td>\n",
       "      <td>0.769300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>66</td>\n",
       "      <td>0.950900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>67</td>\n",
       "      <td>0.731000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>68</td>\n",
       "      <td>2.125400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>69</td>\n",
       "      <td>1.005000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>70</td>\n",
       "      <td>0.758300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>71</td>\n",
       "      <td>1.368200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>72</td>\n",
       "      <td>0.549600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>73</td>\n",
       "      <td>0.538500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>74</td>\n",
       "      <td>0.995500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.972100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>76</td>\n",
       "      <td>1.792200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>77</td>\n",
       "      <td>0.729800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>78</td>\n",
       "      <td>1.058000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>79</td>\n",
       "      <td>0.931200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>80</td>\n",
       "      <td>0.822300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>81</td>\n",
       "      <td>1.669200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>82</td>\n",
       "      <td>1.509300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>83</td>\n",
       "      <td>1.743500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>84</td>\n",
       "      <td>1.279300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>85</td>\n",
       "      <td>0.673300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>86</td>\n",
       "      <td>1.085400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>87</td>\n",
       "      <td>1.105800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>88</td>\n",
       "      <td>1.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>89</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>1.091500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>91</td>\n",
       "      <td>0.975900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>92</td>\n",
       "      <td>1.154200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>93</td>\n",
       "      <td>1.451400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>94</td>\n",
       "      <td>0.745300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>95</td>\n",
       "      <td>0.838700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>96</td>\n",
       "      <td>1.065000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>97</td>\n",
       "      <td>1.578900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>98</td>\n",
       "      <td>0.487500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>99</td>\n",
       "      <td>1.483000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.296000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>101</td>\n",
       "      <td>1.120700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>102</td>\n",
       "      <td>1.175200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>103</td>\n",
       "      <td>1.031100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>104</td>\n",
       "      <td>0.812700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.878300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>106</td>\n",
       "      <td>0.610400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>107</td>\n",
       "      <td>0.852300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>108</td>\n",
       "      <td>0.649400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>109</td>\n",
       "      <td>0.936500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>110</td>\n",
       "      <td>0.733500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>111</td>\n",
       "      <td>1.054600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>112</td>\n",
       "      <td>1.188000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>113</td>\n",
       "      <td>1.500700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>114</td>\n",
       "      <td>0.521100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>115</td>\n",
       "      <td>1.379100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>116</td>\n",
       "      <td>1.023300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>117</td>\n",
       "      <td>0.907500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>118</td>\n",
       "      <td>0.832800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>119</td>\n",
       "      <td>0.646900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.777800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>121</td>\n",
       "      <td>0.867000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>122</td>\n",
       "      <td>0.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>123</td>\n",
       "      <td>1.040500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>124</td>\n",
       "      <td>0.992200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>125</td>\n",
       "      <td>0.780200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>126</td>\n",
       "      <td>0.800600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>127</td>\n",
       "      <td>0.701700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>128</td>\n",
       "      <td>0.773200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>129</td>\n",
       "      <td>0.676100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>130</td>\n",
       "      <td>0.780800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>131</td>\n",
       "      <td>1.508700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>132</td>\n",
       "      <td>1.178800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>133</td>\n",
       "      <td>0.631600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>134</td>\n",
       "      <td>0.951400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.939600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>136</td>\n",
       "      <td>0.804700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>137</td>\n",
       "      <td>1.218600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>138</td>\n",
       "      <td>0.967700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>139</td>\n",
       "      <td>1.669800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>140</td>\n",
       "      <td>1.030000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>141</td>\n",
       "      <td>0.992700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>142</td>\n",
       "      <td>0.790900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>143</td>\n",
       "      <td>1.232600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>144</td>\n",
       "      <td>0.749000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>145</td>\n",
       "      <td>0.830500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>146</td>\n",
       "      <td>0.811300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>147</td>\n",
       "      <td>0.707800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>148</td>\n",
       "      <td>1.524200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>149</td>\n",
       "      <td>0.736700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.723500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>151</td>\n",
       "      <td>0.657900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>152</td>\n",
       "      <td>1.251000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>153</td>\n",
       "      <td>0.366200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>154</td>\n",
       "      <td>1.020500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>155</td>\n",
       "      <td>0.849700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>156</td>\n",
       "      <td>0.738400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>157</td>\n",
       "      <td>1.141400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>158</td>\n",
       "      <td>1.249100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>159</td>\n",
       "      <td>0.829400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>160</td>\n",
       "      <td>0.838400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>161</td>\n",
       "      <td>0.784500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>162</td>\n",
       "      <td>0.710900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>163</td>\n",
       "      <td>0.918100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>164</td>\n",
       "      <td>1.006100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>1.225300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>166</td>\n",
       "      <td>1.488300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>167</td>\n",
       "      <td>0.666900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>168</td>\n",
       "      <td>0.826200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>169</td>\n",
       "      <td>0.484000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>170</td>\n",
       "      <td>0.737800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>171</td>\n",
       "      <td>1.066700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>172</td>\n",
       "      <td>0.682200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>173</td>\n",
       "      <td>0.931500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>174</td>\n",
       "      <td>0.450200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>175</td>\n",
       "      <td>0.328700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>176</td>\n",
       "      <td>1.444900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>177</td>\n",
       "      <td>1.685500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>178</td>\n",
       "      <td>0.956100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>179</td>\n",
       "      <td>0.967500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.796800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>181</td>\n",
       "      <td>0.871400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>182</td>\n",
       "      <td>0.605700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>183</td>\n",
       "      <td>1.036500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>184</td>\n",
       "      <td>0.868000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>185</td>\n",
       "      <td>0.707600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>186</td>\n",
       "      <td>1.221800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>187</td>\n",
       "      <td>0.541200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>188</td>\n",
       "      <td>0.362400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>189</td>\n",
       "      <td>0.588100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>190</td>\n",
       "      <td>0.732600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>191</td>\n",
       "      <td>0.644600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>192</td>\n",
       "      <td>0.626400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>193</td>\n",
       "      <td>0.631700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>194</td>\n",
       "      <td>0.504300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.646000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>196</td>\n",
       "      <td>0.565100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>197</td>\n",
       "      <td>0.921300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>198</td>\n",
       "      <td>0.696100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>199</td>\n",
       "      <td>0.507500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.569900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>201</td>\n",
       "      <td>0.988700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>202</td>\n",
       "      <td>0.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>203</td>\n",
       "      <td>0.609700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>204</td>\n",
       "      <td>1.218200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>205</td>\n",
       "      <td>1.309200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>206</td>\n",
       "      <td>0.538600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>207</td>\n",
       "      <td>1.014400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>208</td>\n",
       "      <td>0.375900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>209</td>\n",
       "      <td>0.985500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.529100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>211</td>\n",
       "      <td>0.584000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>212</td>\n",
       "      <td>0.467100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>213</td>\n",
       "      <td>0.544200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>214</td>\n",
       "      <td>0.673800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>215</td>\n",
       "      <td>0.712800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>216</td>\n",
       "      <td>0.877800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>217</td>\n",
       "      <td>1.076000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>218</td>\n",
       "      <td>0.998900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>219</td>\n",
       "      <td>0.762300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>220</td>\n",
       "      <td>0.372500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>221</td>\n",
       "      <td>0.405200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>222</td>\n",
       "      <td>1.108700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>223</td>\n",
       "      <td>1.436400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>224</td>\n",
       "      <td>0.665800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>225</td>\n",
       "      <td>0.827200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>226</td>\n",
       "      <td>0.669400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>227</td>\n",
       "      <td>0.962400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>228</td>\n",
       "      <td>0.486500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>229</td>\n",
       "      <td>0.996300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>230</td>\n",
       "      <td>1.042200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>231</td>\n",
       "      <td>0.598400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>232</td>\n",
       "      <td>0.966600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>233</td>\n",
       "      <td>0.657500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>234</td>\n",
       "      <td>1.494900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>235</td>\n",
       "      <td>0.818800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>236</td>\n",
       "      <td>1.153900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>237</td>\n",
       "      <td>0.895800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>238</td>\n",
       "      <td>0.631900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>239</td>\n",
       "      <td>0.863200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>240</td>\n",
       "      <td>0.712000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda3\\envs\\pytorch2.3.0\\Lib\\site-packages\\peft\\utils\\other.py:1110: UserWarning: Unable to fetch remote file due to the following error (MaxRetryError(\"HTTPSConnectionPool(host='huggingface.co', port=443): Max retries exceeded with url: /Qwen/Qwen1.5-0.5B/resolve/main/config.json (Caused by ConnectTimeoutError(<urllib3.connection.HTTPSConnection object at 0x0000022F1E7B8F10>, 'Connection to huggingface.co timed out. (connect timeout=10)'))\"), '(Request ID: feff0af3-b0d0-4073-a947-c225475e55a1)') - silently ignoring the lookup for the file config.json in Qwen/Qwen1.5-0.5B.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LoRA å¾®è°ƒå®Œæˆ, æƒé‡ä¿å­˜åœ¨ lora-5epoch\n"
     ]
    }
   ],
   "source": [
    "def train_lora(epochs, output_dir):\n",
    "    base_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    config = LoraConfig(\n",
    "        r=4,\n",
    "        lora_alpha=16,\n",
    "        target_modules=[\"q_proj\", \"v_proj\"],\n",
    "        lora_dropout=0.1\n",
    "    )\n",
    "    model = get_peft_model(base_model, config)\n",
    "    data_collator = DataCollatorForLanguageModeling(\n",
    "    tokenizer=tokenizer, \n",
    "    mlm=False  # è®¾ç½®ä¸º False ä»¥é€‚é… Causal LM\n",
    ")\n",
    "    args = TrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        num_train_epochs=epochs,\n",
    "        per_device_train_batch_size=4,\n",
    "        save_strategy=\"no\",\n",
    "        remove_unused_columns=False,\n",
    "        logging_steps=1,\n",
    "        learning_rate=2e-4,\n",
    "        fp16=False,\n",
    "    )\n",
    "    trainer = Trainer(\n",
    "        model=model,\n",
    "        args=args,\n",
    "        train_dataset=tokenized_data,\n",
    "        data_collator=data_collator,\n",
    "    )\n",
    "    trainer.train()\n",
    "    model.save_pretrained(output_dir)\n",
    "    print(f\"LoRA å¾®è°ƒå®Œæˆ, æƒé‡ä¿å­˜åœ¨ {output_dir}\")\n",
    "\n",
    "def infer(model, prompt):\n",
    "    device = torch.device(\"cpu\")\n",
    "    model = model.to(device)\n",
    "    assert isinstance(prompt, str), \"Prompt must be a string!\"\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", padding=True, truncation=True, max_length=512).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model.generate(\n",
    "            **inputs,\n",
    "            max_new_tokens=128,\n",
    "            do_sample=False,\n",
    "            pad_token_id=tokenizer.eos_token_id\n",
    "        )\n",
    "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    return result\n",
    "\n",
    "def plot_answer_comparison(question, answers, labels, filename):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.title(f\"é—®é¢˜ï¼š{question}\")\n",
    "    plt.axis(\"off\")\n",
    "    y0 = 1.0\n",
    "    for ans, label in zip(answers, labels):\n",
    "        plt.text(0, y0, f\"{label}:\\n{ans}\", fontsize=12, verticalalignment=\"top\")\n",
    "        y0 -= 0.35\n",
    "    plt.savefig(filename, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    print(f\"å·²ä¿å­˜å¯¹æ¯”å›¾ï¼š{filename}\")\n",
    "if __name__ == \"__main__\":\n",
    "    # -------------------\n",
    "    # è®­ç»ƒé˜¶æ®µ\n",
    "    # -------------------\n",
    "    # è®­ç»ƒ5è½®å’Œ10è½®çš„LoRAæ¨¡å‹\n",
    "    if not os.path.exists(\"lora-5epoch\"):\n",
    "        train_lora(5, \"lora-5epoch\")\n",
    "    if not os.path.exists(\"lora-10epoch\"):\n",
    "        train_lora(10, \"lora-10epoch\")\n",
    "\n",
    "    # -------------------\n",
    "    # æ¨ç†ä¸ç»“æœåˆ†æ\n",
    "    # -------------------\n",
    "    # é€‰æ‹©ä¸€ä¸ªé—®é¢˜è¿›è¡Œåˆ†æï¼ˆå¯è‡ªè¡Œæ›¿æ¢ä¸ºå®é™…é—®é¢˜ï¼‰\n",
    "    test_question = \"è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚\"\n",
    "\n",
    "    # 1. åŸå§‹Qwenæ¨¡å‹å›ç­”\n",
    "    original_model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "    orig_answer = infer(original_model, test_question)\n",
    "\n",
    "    # 2. LoRA å¾®è°ƒæ¨¡å‹ï¼ˆ5è½®ï¼‰\n",
    "    lora5_model = PeftModel.from_pretrained(\n",
    "        AutoModelForCausalLM.from_pretrained(model_name),\n",
    "        \"lora-5epoch\"\n",
    "    )\n",
    "    lora5_answer = infer(lora5_model, test_question)\n",
    "\n",
    "    # 3. LoRA å¾®è°ƒæ¨¡å‹ï¼ˆ10è½®ï¼‰\n",
    "    lora10_model = PeftModel.from_pretrained(\n",
    "        AutoModelForCausalLM.from_pretrained(model_name),\n",
    "        \"lora-10epoch\"\n",
    "    )\n",
    "    lora10_answer = infer(lora10_model, test_question)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ä»»åŠ¡ 3ï¼šå¾®è°ƒæ•ˆæœåˆ†æ\n",
    "\n",
    "#### é—®é¢˜ 5ï¼šè®­ç»ƒå‰åå›ç­”å¯¹æ¯”\n",
    "- ç”¨åŸå§‹æ¨¡å‹å’Œ5è½®è®­ç»ƒåçš„æ¨¡å‹ï¼Œå›ç­”åŒä¸€é—®é¢˜ï¼Œå¯¹æ¯”ç»“æœã€‚\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "é—®é¢˜: è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚\n",
      "==================================================\n",
      "\n",
      "ã€åŸå§‹Qwenæ¨¡å‹å›ç­”ã€‘\n",
      "è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚LoRAçš„åŸºæœ¬æ€æƒ³æ˜¯ï¼šï¼ˆ1ï¼‰åœ¨LoRAä¸­ï¼Œæ¯ä¸ªç”¨æˆ·éƒ½æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„IDï¼ŒIDæ˜¯å”¯ä¸€çš„ï¼Œä¸”ä¸å¯æ›´æ”¹ï¼›ï¼ˆ2ï¼‰æ¯ä¸ªç”¨æˆ·éƒ½æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„IPåœ°å€ï¼ŒIPåœ°å€æ˜¯å”¯ä¸€çš„ï¼Œä¸”ä¸å¯æ›´æ”¹ï¼›ï¼ˆ3ï¼‰æ¯ä¸ªç”¨æˆ·éƒ½æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„MACåœ°å€ï¼ŒMACåœ°å€æ˜¯å”¯ä¸€çš„ï¼Œä¸”ä¸å¯æ›´æ”¹ï¼›ï¼ˆ4ï¼‰æ¯ä¸ªç”¨æˆ·éƒ½æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„IPåœ°å€å’ŒMACåœ°å€ï¼ŒIPåœ°å€å’ŒMACåœ°å€æ˜¯ä¸å¯æ›´æ”¹çš„ï¼›ï¼ˆ5ï¼‰æ¯ä¸ªç”¨æˆ·éƒ½æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„IDï¼ŒIDæ˜¯å”¯ä¸€çš„ï¼Œä¸”ä¸å¯æ›´æ”¹ï¼›ï¼ˆ6ï¼‰æ¯ä¸ªç”¨æˆ·éƒ½æ‹¥æœ‰ä¸€ä¸ªå”¯ä¸€çš„IPåœ°å€å’Œ\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ã€LoRAå¾®è°ƒåï¼ˆ10è½®ï¼‰å›ç­”ã€‘\n",
      "è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚ LoRAçš„åŸºæœ¬æ€æƒ³æ˜¯å°†æ‰€æœ‰äº¤æ˜“éƒ½è®°å½•åœ¨ä¸€å¼ ç¥¨æ®ä¸Šï¼Œç„¶åå°†ç¥¨æ®ä¸ç¥¨æ®è¿›è¡Œæ¯”è¾ƒï¼Œä»¥ç¡®å®šäº¤æ˜“æ˜¯å¦åˆæ³•ã€‚è¿™ç§åšæ³•å¯ä»¥ç¡®ä¿äº¤æ˜“çš„åˆæ³•æ€§ï¼Œå¹¶ä¸”å¯ä»¥é˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚LoRAè¿˜å…è®¸äº¤æ˜“è€…åœ¨ç¥¨æ®ä¸Šæ·»åŠ å…¶ä»–ä¿¡æ¯ï¼Œä¾‹å¦‚äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡‘é¢ã€äº¤æ˜“åœ°ç‚¹ç­‰ã€‚è¿™ç§åšæ³•å¯ä»¥æé«˜äº¤æ˜“è€…çš„ä¿¡ä»»åº¦ï¼Œå¹¶ä¸”å¯ä»¥é˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚LoRAè¿˜å…è®¸äº¤æ˜“è€…åœ¨ç¥¨æ®ä¸Šæ·»åŠ å…¶ä»–ä¿¡æ¯ï¼Œä¾‹å¦‚äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡‘é¢ã€äº¤æ˜“åœ°ç‚¹ç­‰ã€‚è¿™ç§åšæ³•å¯ä»¥æé«˜äº¤æ˜“è€…çš„ä¿¡ä»»åº¦ï¼Œå¹¶ä¸”å¯ä»¥é˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "# é—®é¢˜5ï¼šè®­ç»ƒå‰åå¯¹æ¯”\n",
    "# é—®é¢˜5ï¼šè®­ç»ƒå‰åå¯¹æ¯” - ç›´æ¥æŸ¥çœ‹æ–‡æœ¬è¾“å‡º\n",
    "test_question = \"è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"é—®é¢˜: {test_question}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nã€åŸå§‹Qwenæ¨¡å‹å›ç­”ã€‘\")\n",
    "print(orig_answer)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"ã€LoRAå¾®è°ƒåï¼ˆ10è½®ï¼‰å›ç­”ã€‘\")\n",
    "print(lora5_answer)\n",
    "print(\"=\"*50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "é—®é¢˜: è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚\n",
      "==================================================\n",
      "\n",
      "ã€LoRAå¾®è°ƒåï¼ˆ5è½®ï¼‰å›ç­”ã€‘\n",
      "è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚ LoRAçš„åŸºæœ¬æ€æƒ³æ˜¯å°†æ‰€æœ‰äº¤æ˜“éƒ½è®°å½•åœ¨ä¸€å¼ ç¥¨æ®ä¸Šï¼Œç„¶åå°†ç¥¨æ®ä¸ç¥¨æ®è¿›è¡Œæ¯”è¾ƒï¼Œä»¥ç¡®å®šäº¤æ˜“æ˜¯å¦åˆæ³•ã€‚è¿™ç§åšæ³•å¯ä»¥ç¡®ä¿äº¤æ˜“çš„åˆæ³•æ€§ï¼Œå¹¶ä¸”å¯ä»¥é˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚LoRAè¿˜å…è®¸äº¤æ˜“è€…åœ¨ç¥¨æ®ä¸Šæ·»åŠ å…¶ä»–ä¿¡æ¯ï¼Œä¾‹å¦‚äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡‘é¢ã€äº¤æ˜“åœ°ç‚¹ç­‰ã€‚è¿™ç§åšæ³•å¯ä»¥æé«˜äº¤æ˜“è€…çš„ä¿¡ä»»åº¦ï¼Œå¹¶ä¸”å¯ä»¥é˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚LoRAè¿˜å…è®¸äº¤æ˜“è€…åœ¨ç¥¨æ®ä¸Šæ·»åŠ å…¶ä»–ä¿¡æ¯ï¼Œä¾‹å¦‚äº¤æ˜“æ—¥æœŸã€äº¤æ˜“é‡‘é¢ã€äº¤æ˜“åœ°ç‚¹ç­‰ã€‚è¿™ç§åšæ³•å¯ä»¥æé«˜äº¤æ˜“è€…çš„ä¿¡ä»»åº¦ï¼Œå¹¶ä¸”å¯ä»¥é˜²æ­¢æ¬ºè¯ˆè¡Œä¸ºã€‚\n",
      "\n",
      "--------------------------------------------------\n",
      "\n",
      "ã€LoRAå¾®è°ƒåï¼ˆ10è½®ï¼‰å›ç­”ã€‘\n",
      "è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚ LoRAçš„åŸºæœ¬æ€æƒ³æ˜¯å°†æ‰€æœ‰ä¸šåŠ¡æµç¨‹è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œå°†æ¯ä¸ªä¸šåŠ¡æµç¨‹è§†ä¸ºä¸€ä¸ªç‹¬ç«‹çš„å®ä½“ã€‚è¿™ä¸ªå®ä½“å¯ä»¥æ˜¯ä»»ä½•å®ä½“ï¼ŒåŒ…æ‹¬å®¢æˆ·ã€ä¾›åº”å•†ã€åˆä½œä¼™ä¼´ã€å‘˜å·¥ã€æ”¿åºœæœºæ„ç­‰ã€‚LoRA çš„æ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸šåŠ¡æµç¨‹è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œä»¥å®ç°ä¸šåŠ¡æµç¨‹çš„è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–ã€‚é€šè¿‡ä½¿ç”¨è‡ªåŠ¨åŒ–å·¥å…·å’ŒæŠ€æœ¯ï¼ŒLoRA å¯ä»¥å®ç°ä¸šåŠ¡æµç¨‹çš„è‡ªåŠ¨åŒ–å’Œæ ‡å‡†åŒ–ï¼Œä»è€Œæé«˜æ•ˆç‡å’Œé™ä½æˆæœ¬ã€‚LoRA çš„å¦ä¸€ä¸ªæ ¸å¿ƒæ€æƒ³æ˜¯å°†ä¸šåŠ¡æµç¨‹è§†ä¸ºä¸€ä¸ªæ•´ä½“ï¼Œä»¥å®ç°ä¸šåŠ¡æµç¨‹çš„æ ‡å‡†åŒ–å’Œè‡ªåŠ¨åŒ–ã€‚é€šè¿‡ä½¿ç”¨è‡ªåŠ¨åŒ–å·¥å…·å’ŒæŠ€æœ¯ï¼ŒLoRA å¯ä»¥å®ç°ä¸šåŠ¡æµç¨‹çš„\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# é—®é¢˜6ï¼š5è½®å’Œ10è½®å¯¹æ¯” - ç›´æ¥æŸ¥çœ‹æ–‡æœ¬è¾“å‡º\n",
    "test_question = \"è¯·ç®€è¿°LoRAçš„åŸºæœ¬æ€æƒ³ã€‚\"\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(f\"é—®é¢˜: {test_question}\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "print(\"\\nã€LoRAå¾®è°ƒåï¼ˆ5è½®ï¼‰å›ç­”ã€‘\")\n",
    "print(lora5_answer)\n",
    "\n",
    "print(\"\\n\" + \"-\"*50 + \"\\n\")\n",
    "\n",
    "print(\"ã€LoRAå¾®è°ƒåï¼ˆ10è½®ï¼‰å›ç­”ã€‘\")\n",
    "print(lora10_answer)\n",
    "print(\"=\"*50) # é—®é¢˜6ï¼š5è½®å’Œ10è½®å¯¹æ¯”\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch2.3.0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
